{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 3 : *Data Modelling* \n",
    "This notebook is for modelling. \n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "## Table of contents \n",
    "\n",
    "### 1. Data preparation\n",
    " - 1.1 Load Data\n",
    " - 1.2 Optimize memory\n",
    " \n",
    "### 2. Building  Light Gradient Boosting model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "## 1.1 Load feature engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.1)\n",
    "sns.set_style('whitegrid')\n",
    "from datetime import datetime \n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (8921483, 60)\n",
      "Test data: (7853253, 59)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:/Users/dj.lee/Desktop/data/train/train_preprocessing.csv')\n",
    "print('Train data:', df_train.shape)\n",
    "\n",
    "df_test = pd.read_csv('C:/Users/dj.lee/Desktop/data/test/test_preprocessing.csv')\n",
    "print('Test data:', df_test.shape)\n",
    "\n",
    "del df_train['Date']\n",
    "del df_train['MachineIdentifier']\n",
    "\n",
    "del df_test['Date']\n",
    "del df_test['MachineIdentifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Lag_from_Start'].fillna(df_train['Lag_from_Start'].mode()[0], inplace=True)\n",
    "df_test['Lag_from_Start'].fillna(df_test['Lag_from_Start'].mode()[0], inplace=True)\n",
    "\n",
    "df_train['Hard_Ratio_for_OS'].fillna(df_train['Hard_Ratio_for_OS'].mode()[0], inplace=True)\n",
    "df_test['Hard_Ratio_for_OS'].fillna(df_test['Hard_Ratio_for_OS'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Optimize memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df,f):\n",
    "    mx = df[f].max()\n",
    "    if mx < 256:\n",
    "            df[f] = df[f].astype('uint8')\n",
    "    elif mx < 65536:\n",
    "        df[f] = df[f].astype('uint16')\n",
    "    else:\n",
    "        df[f] = df[f].astype('uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = list(df_train.columns)\n",
    "used_features.remove('HasDetections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing memory...\n"
     ]
    }
   ],
   "source": [
    "print('Optimizing memory...')\n",
    "for f in used_features:\n",
    "    reduce_memory(df_train, f)\n",
    "    reduce_memory(df_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Light Gradient Boosting model\n",
    "In this project, I build light gradient boosting model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### FOLD  1 #########\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.72292\tvalid_0's binary_logloss: 0.608365\n",
      "[400]\tvalid_0's auc: 0.724495\tvalid_0's binary_logloss: 0.606954\n",
      "[600]\tvalid_0's auc: 0.724797\tvalid_0's binary_logloss: 0.60669\n",
      "[800]\tvalid_0's auc: 0.724868\tvalid_0's binary_logloss: 0.606636\n",
      "Early stopping, best iteration is:\n",
      "[831]\tvalid_0's auc: 0.724884\tvalid_0's binary_logloss: 0.606624\n",
      "Predicting test...\n",
      "####### FOLD  2 #########\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.722532\tvalid_0's binary_logloss: 0.6088\n",
      "[400]\tvalid_0's auc: 0.724062\tvalid_0's binary_logloss: 0.607432\n",
      "[600]\tvalid_0's auc: 0.724332\tvalid_0's binary_logloss: 0.607178\n",
      "[800]\tvalid_0's auc: 0.724383\tvalid_0's binary_logloss: 0.607119\n",
      "Early stopping, best iteration is:\n",
      "[754]\tvalid_0's auc: 0.724395\tvalid_0's binary_logloss: 0.607114\n",
      "Predicting test...\n",
      "####### FOLD  3 #########\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.723058\tvalid_0's binary_logloss: 0.608305\n",
      "[400]\tvalid_0's auc: 0.724578\tvalid_0's binary_logloss: 0.606954\n",
      "[600]\tvalid_0's auc: 0.724876\tvalid_0's binary_logloss: 0.606681\n",
      "[800]\tvalid_0's auc: 0.72492\tvalid_0's binary_logloss: 0.606621\n",
      "Early stopping, best iteration is:\n",
      "[772]\tvalid_0's auc: 0.724938\tvalid_0's binary_logloss: 0.606609\n",
      "Predicting test...\n",
      "####### FOLD  4 #########\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.723539\tvalid_0's binary_logloss: 0.607901\n",
      "[400]\tvalid_0's auc: 0.725045\tvalid_0's binary_logloss: 0.606528\n",
      "[600]\tvalid_0's auc: 0.72539\tvalid_0's binary_logloss: 0.606232\n",
      "[800]\tvalid_0's auc: 0.725466\tvalid_0's binary_logloss: 0.606154\n",
      "Early stopping, best iteration is:\n",
      "[860]\tvalid_0's auc: 0.725478\tvalid_0's binary_logloss: 0.60614\n",
      "Predicting test...\n",
      "####### FOLD  5 #########\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.723392\tvalid_0's binary_logloss: 0.608114\n",
      "[400]\tvalid_0's auc: 0.724916\tvalid_0's binary_logloss: 0.606747\n",
      "[600]\tvalid_0's auc: 0.725216\tvalid_0's binary_logloss: 0.60648\n",
      "[800]\tvalid_0's auc: 0.725268\tvalid_0's binary_logloss: 0.606439\n",
      "Early stopping, best iteration is:\n",
      "[723]\tvalid_0's auc: 0.725276\tvalid_0's binary_logloss: 0.606433\n",
      "Predicting test...\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "\n",
    "pred_val = np.zeros(len(df_test))\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "selected_features = used_features\n",
    "\n",
    "ct = 0\n",
    "for idxT, idxV in folds.split(df_train[selected_features], df_train['HasDetections']):\n",
    "    # TRAIN LGBM\n",
    "    ct += 1; print('####### FOLD ',ct,'#########')\n",
    "    df_trainA = df_train.loc[idxT]\n",
    "    df_trainB = df_train.loc[idxV]\n",
    "    model = lgb.LGBMClassifier(n_estimators=10000, colsample_bytree=0.5, objective='binary', num_leaves=2048,\n",
    "            max_depth=-1, learning_rate=0.04)\n",
    "    h=model.fit(df_trainA[selected_features], df_trainA['HasDetections'], eval_metric='auc',\n",
    "            eval_set=[(df_trainB[selected_features], df_trainB['HasDetections'])], verbose=200,\n",
    "            early_stopping_rounds=100)\n",
    "    \n",
    "    # PREDICT TEST\n",
    "    del df_trainA, df_trainB; x=gc.collect()\n",
    "    idx = 0; ct2 = 1; chunk = 200\n",
    "    print('Predicting test...')\n",
    "    while idx < len(df_test):\n",
    "        idx2 = min(idx + chunk, len(df_test))\n",
    "        idx = range(idx, idx2)\n",
    "        pred_val[idx] += model.predict_proba(df_test.iloc[idx][selected_features])[:,1]\n",
    "        #print('Finished predicting part',ct2)\n",
    "        ct2 += 1; idx = idx2\n",
    "\n",
    "pred_val_final = pred_val/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id_data = pd.read_csv('C:/Users/dj.lee/Desktop/data/test/test.csv', usecols=['MachineIdentifier'])\n",
    "\n",
    "pre = pd.DataFrame({'MachineIdentifier': Id_data['MachineIdentifier'], 'HasDetections': pred_val_final})\n",
    "pre.to_csv('C:/Users/dj.lee/Desktop/data/test/pre_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 3000000\n",
    "SGD = SGDClassifier(loss='log')\n",
    "\n",
    "for df_train in pd.read_csv('C:/Users/dj.lee/Desktop/data/train/train_preprocessing.csv', chunksize=chunksize, iterator=True):\n",
    "    del df_train['Date']\n",
    "    del df_train['MachineIdentifier']\n",
    "    df_train['Lag_from_Start'].fillna(df_train['Lag_from_Start'].mode()[0], inplace=True)\n",
    "    df_train['Hard_Ratio_for_OS'].fillna(df_train['Hard_Ratio_for_OS'].mode()[0], inplace=True)\n",
    "    used_features = df_train.columns.tolist()\n",
    "    used_features.remove('HasDetections')\n",
    "    \n",
    "    X = df_train[used_features]\n",
    "    Y = df_train['HasDetections']\n",
    "    SGD.partial_fit(X, Y, classes=np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = SGD.predict_proba(df_test)\n",
    "result_sgdc = pred_val[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_lgbm = pd.read_csv('C:/Users/dj.lee/Desktop/data/test/pre_lgbm.csv')\n",
    "result = pd.DataFrame({'MachineIdentifier':result_lgbm['MachineIdentifier'] ,'lgbm':result_lgbm['HasDetections'], 'sgdc':result_sgdc })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = result_lgbm['HasDetections'] > 0.5\n",
    "lgbm = np.array(lgbm).astype(float)\n",
    "result['lgbm_01'] = lgbm\n",
    "\n",
    "sgdc = np.array(result_sgdc)  > 0.5\n",
    "sgdc = sgdc.astype(float)\n",
    "result['sgdc_01'] = sgdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.591196412493014"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(result['lgbm_01'] == result['sgdc_01']) / len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
